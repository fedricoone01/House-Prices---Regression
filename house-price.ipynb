{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Data analysis and wrangling\nimport os\nimport warnings\nimport numpy as np\nimport pandas as pd\nfrom datetime import datetime\nfrom typing import Dict, List, Tuple, Sequence\n\n# Visualization\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport matplotlib.gridspec as gridspec\nfrom matplotlib.ticker import MaxNLocator\n\n# Machine learning\nfrom scipy import stats\nfrom scipy.stats import skew, boxcox_normmax, norm\nfrom scipy.special import boxcox1p\n\nfrom sklearn.ensemble import GradientBoostingRegressor, HistGradientBoostingRegressor\nfrom sklearn.linear_model import ElasticNetCV, LassoCV, RidgeCV, TweedieRegressor\nfrom sklearn.model_selection import cross_val_score, KFold, cross_validate\nfrom sklearn.experimental import enable_hist_gradient_boosting\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.svm import SVR\n\nfrom mlxtend.regressor import StackingCVRegressor\nfrom lightgbm import LGBMRegressor\nfrom xgboost import XGBRegressor\n\n\nwarnings.filterwarnings('ignore')\n\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-09-07T14:03:26.287256Z","iopub.execute_input":"2022-09-07T14:03:26.288158Z","iopub.status.idle":"2022-09-07T14:03:29.205125Z","shell.execute_reply.started":"2022-09-07T14:03:26.288029Z","shell.execute_reply":"2022-09-07T14:03:29.204200Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"pd.options.display.max_columns = 250\npd.options.display.max_rows = 250\n\ntrain_data = pd.read_csv(\"/kaggle/input/house-prices-advanced-regression-techniques/train.csv\")\ntest_data = pd.read_csv(\"/kaggle/input/house-prices-advanced-regression-techniques/test.csv\")\n\ntrain_data.head()","metadata":{"execution":{"iopub.status.busy":"2022-09-07T14:03:29.206828Z","iopub.execute_input":"2022-09-07T14:03:29.207403Z","iopub.status.idle":"2022-09-07T14:03:29.341293Z","shell.execute_reply.started":"2022-09-07T14:03:29.207373Z","shell.execute_reply":"2022-09-07T14:03:29.340047Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# 1. Exploratory Data Analysis","metadata":{}},{"cell_type":"code","source":"train_data.describe().round(2)","metadata":{"execution":{"iopub.status.busy":"2022-09-07T14:03:29.342657Z","iopub.execute_input":"2022-09-07T14:03:29.343096Z","iopub.status.idle":"2022-09-07T14:03:29.491397Z","shell.execute_reply.started":"2022-09-07T14:03:29.343065Z","shell.execute_reply":"2022-09-07T14:03:29.489995Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"print(train_data.size)\n\nprint(train_data.shape)\n\ntrain_data.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2022-09-07T14:03:29.495332Z","iopub.execute_input":"2022-09-07T14:03:29.495702Z","iopub.status.idle":"2022-09-07T14:03:29.510768Z","shell.execute_reply.started":"2022-09-07T14:03:29.495668Z","shell.execute_reply":"2022-09-07T14:03:29.509966Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"train_data['YrSold'].unique()","metadata":{"execution":{"iopub.status.busy":"2022-09-07T14:03:29.514547Z","iopub.execute_input":"2022-09-07T14:03:29.514934Z","iopub.status.idle":"2022-09-07T14:03:29.521272Z","shell.execute_reply.started":"2022-09-07T14:03:29.514900Z","shell.execute_reply":"2022-09-07T14:03:29.520440Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"**1.1 Numeric features**","metadata":{}},{"cell_type":"code","source":"#We do a correlation analysis\n#Here only the \"numeric\" variables are appreciated and not the CATEGORICAL ones.\n\nplt.style.use('fivethirtyeight')\n\nsns.set(font_scale=1.1)\ncorrelation_train = train_data.corr()\nmask = np.triu(correlation_train.corr())\nplt.figure(figsize=(20, 20))\nsns.heatmap(correlation_train,\n            annot=True,\n            fmt='.1f',\n            cmap='coolwarm',\n            square=True,\n            mask=mask,\n            linewidths=1,\n            cbar=False)\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-09-07T14:03:29.522255Z","iopub.execute_input":"2022-09-07T14:03:29.523135Z","iopub.status.idle":"2022-09-07T14:03:32.801854Z","shell.execute_reply.started":"2022-09-07T14:03:29.523104Z","shell.execute_reply":"2022-09-07T14:03:32.801040Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# One of the best ways to see how they affect selling prices are \"scatter plots\".\n# We are also plotting polynomial regression lines to see the general trend.\n# In this way we can understand the numerical values and their importance in the sale price.\n# Also very useful for --> detecting outliers <--.\n\ndef srt_reg(y, df):\n    fig, axes = plt.subplots(12, 3, figsize=(25, 80))\n    axes = axes.flatten()\n\n    for i, j in zip(df.select_dtypes(include=['number']).columns, axes):\n\n        sns.regplot(x=i,\n                    y=y,\n                    data=df,\n                    ax=j,\n                    order=3,\n                    ci=None,\n                    color='#e74c3c',\n                    line_kws={'color': 'black'},\n                    scatter_kws={'alpha':0.4})\n        j.tick_params(labelrotation=45)\n        j.yaxis.set_major_locator(MaxNLocator(nbins=10))\n\n        plt.tight_layout()\n\nsrt_reg('SalePrice', train_data)","metadata":{"execution":{"iopub.status.busy":"2022-09-07T14:03:32.803169Z","iopub.execute_input":"2022-09-07T14:03:32.803647Z","iopub.status.idle":"2022-09-07T14:04:11.027737Z","shell.execute_reply.started":"2022-09-07T14:03:32.803617Z","shell.execute_reply":"2022-09-07T14:04:11.026420Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# Remove outliers (after detecting them with the naked eye).\n\n\ntrain_data = train_data.drop(train_data[(train_data['OverallQual'] < 5) & (train_data['SalePrice'] > 200000)].index)\n\ntrain_data = train_data.drop(train_data[(train_data['GrLivArea'] > 4000)& (train_data['SalePrice'] < 200000)].index)\n\ntrain_data = train_data.drop(train_data[(train_data['GarageArea'] > 1200)& (train_data['SalePrice'] < 200000)].index)\n\ntrain_data = train_data.drop(train_data[(train_data['TotalBsmtSF'] > 3000)& (train_data['SalePrice'] > 320000)].index)\n\ntrain_data = train_data.drop(train_data[(train_data['1stFlrSF'] < 3000)& (train_data['SalePrice'] > 600000)].index)\n\ntrain_data = train_data.drop(train_data[(train_data['1stFlrSF'] > 3000)& (train_data['SalePrice'] < 200000)].index)\n","metadata":{"execution":{"iopub.status.busy":"2022-09-07T14:04:11.029262Z","iopub.execute_input":"2022-09-07T14:04:11.029605Z","iopub.status.idle":"2022-09-07T14:04:11.055284Z","shell.execute_reply.started":"2022-09-07T14:04:11.029575Z","shell.execute_reply":"2022-09-07T14:04:11.054246Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"**1.2 Categorical features**","metadata":{}},{"cell_type":"code","source":"#Now we analyze the \"categorical variables\" in relation to the \"sale price\" of the houses.\n\ndef srt_box(y, df):\n    fig, axes = plt.subplots(14, 3, figsize=(25, 80))\n    axes = axes.flatten()\n\n    for i, j in zip(df.select_dtypes(include=['object']).columns, axes):\n\n        sortd = df.groupby([i])[y].median().sort_values(ascending=False)\n        sns.boxplot(x=i,\n                    y=y,\n                    data=df,\n                    palette='plasma',\n                    order=sortd.index,\n                    ax=j)\n        j.tick_params(labelrotation=45)\n        j.yaxis.set_major_locator(MaxNLocator(nbins=18))\n\n        plt.tight_layout()\n\nsrt_box('SalePrice', train_data)","metadata":{"execution":{"iopub.status.busy":"2022-09-07T14:04:11.056781Z","iopub.execute_input":"2022-09-07T14:04:11.057139Z","iopub.status.idle":"2022-09-07T14:05:02.522238Z","shell.execute_reply.started":"2022-09-07T14:04:11.057109Z","shell.execute_reply":"2022-09-07T14:05:02.520877Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# Extract the target variable from the \"training dataset\"\n\ny = train_data['SalePrice'].reset_index(drop=True)\n\n\n# We join the data, so we don't have to do each transformation operation twice\n\ndataset = pd.concat([train_data, test_data]).reset_index(drop=True)\nprint(dataset.shape)","metadata":{"execution":{"iopub.status.busy":"2022-09-07T14:05:02.523569Z","iopub.execute_input":"2022-09-07T14:05:02.523990Z","iopub.status.idle":"2022-09-07T14:05:02.555487Z","shell.execute_reply.started":"2022-09-07T14:05:02.523960Z","shell.execute_reply":"2022-09-07T14:05:02.554460Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"# 2. Preparing the Data","metadata":{}},{"cell_type":"markdown","source":"**2.1 Missing values**","metadata":{}},{"cell_type":"code","source":"#What we can do is see them raw (as it is above the code) or see them in graphics to visualize them better\n\ndef missing_percentage(df):\n    total = df.isnull().sum().sort_values(ascending=False)[df.isnull().sum().sort_values(ascending=False) != 0]\n    percent = (df.isnull().sum().sort_values(ascending=False) / len(df) *\n                     100)[(df.isnull().sum().sort_values(ascending=False) / len(df) *\n                     100) != 0]\n    return pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n\n\nmissing = missing_percentage(dataset)\n\nfig, ax = plt.subplots(figsize=(20, 5))\nsns.barplot(x=missing.index, y='Percent', data=missing, palette='Reds_r')\nplt.xticks(rotation=90)\n\ndisplay(missing.T.style.background_gradient(cmap='Reds', axis=1))","metadata":{"execution":{"iopub.status.busy":"2022-09-07T14:05:02.556548Z","iopub.execute_input":"2022-09-07T14:05:02.557387Z","iopub.status.idle":"2022-09-07T14:05:03.160720Z","shell.execute_reply.started":"2022-09-07T14:05:02.557350Z","shell.execute_reply":"2022-09-07T14:05:03.159605Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"#Fixed this NaN and null data issue\n\n# List of NaNs, including columns where NaN means \"none\".\nnone_cols = ['Alley', 'PoolQC', 'MiscFeature', 'Fence', 'FireplaceQu', 'GarageType',\n             'GarageFinish', 'GarageQual', 'GarageCond', 'BsmtQual', 'BsmtCond',\n             'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'MasVnrType']\n\n# List of NaNs, including columns where NaN means \"0\".\nzero_cols = ['BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'BsmtFullBath',\n             'BsmtHalfBath', 'GarageYrBlt', 'GarageArea', 'GarageCars', 'MasVnrArea']\n\n# List of NaNs, including columns where NaNs are actually missing, will be replaced with the \"Mode\".\nfreq_cols = ['Electrical', 'Exterior1st', 'Exterior2nd', 'Functional', 'KitchenQual',\n             'SaleType', 'Utilities']\n\n\n# Filling the list of columns above:\n\nfor col in zero_cols:\n    dataset[col].replace(np.nan, 0, inplace=True)\n\nfor col in none_cols:\n    dataset[col].replace(np.nan, 'None', inplace=True)\n\nfor col in freq_cols:\n    dataset[col].replace(np.nan, dataset[col].mode()[0], inplace=True)\n    \n\n# The \"MSZoning\" and \"Lot Frontage\" features are a bit tricky -\n# we fill it with the most common type of each category -\n# isn't perfect, but at least we decreased the randomness a bit.\n\ndataset['MSZoning'] = dataset.groupby('MSSubClass')['MSZoning'].apply(\n    lambda x: x.fillna(x.mode()[0]))\n\n# Filling LotFrontage according to Neighborhood\ndataset['LotFrontage'] = dataset.groupby(\n    ['Neighborhood'])['LotFrontage'].apply(lambda x: x.fillna(x.median()))","metadata":{"execution":{"iopub.status.busy":"2022-09-07T14:05:03.162157Z","iopub.execute_input":"2022-09-07T14:05:03.162499Z","iopub.status.idle":"2022-09-07T14:05:03.216072Z","shell.execute_reply.started":"2022-09-07T14:05:03.162469Z","shell.execute_reply":"2022-09-07T14:05:03.214866Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"**2.2 Dimensionality reduction**","metadata":{}},{"cell_type":"code","source":"# The really weird values that don't seem to add much in general, (appear less than 10 times in our observations) enters the \"Other\" group.\n# Is a dimensionality reduction.\n\nothers = ['Condition1', 'Condition2', 'RoofMatl', 'Exterior1st', 'Exterior2nd',\n          'Heating', 'Electrical', 'Functional', 'SaleType']\n\nfor col in others:\n    mask = dataset[col].isin(dataset[col].value_counts()[dataset[col].value_counts() < 10].index)\n    dataset[col][mask] = 'Other'","metadata":{"execution":{"iopub.status.busy":"2022-09-07T14:05:03.217652Z","iopub.execute_input":"2022-09-07T14:05:03.218192Z","iopub.status.idle":"2022-09-07T14:05:03.259479Z","shell.execute_reply.started":"2022-09-07T14:05:03.218145Z","shell.execute_reply":"2022-09-07T14:05:03.258505Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"**2.3 Convert values**","metadata":{}},{"cell_type":"code","source":"# Convert variable types that are \"numbers\", but should be treated as \"strings\"\n\ndataset['MSSubClass'] = dataset['MSSubClass'].astype(str)\ndataset['YrSold'] = dataset['YrSold'].astype(str)\ndataset['MoSold'] = dataset['MoSold'].astype(str)","metadata":{"execution":{"iopub.status.busy":"2022-09-07T14:05:03.265027Z","iopub.execute_input":"2022-09-07T14:05:03.265917Z","iopub.status.idle":"2022-09-07T14:05:03.279976Z","shell.execute_reply.started":"2022-09-07T14:05:03.265859Z","shell.execute_reply":"2022-09-07T14:05:03.278858Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# Convert CATEGORICAL features to NUMERICS features.\n\n# What is done is grab each Feature and all its possible values -> assign it a number.\n# Where 1 is worse, 2 is better, and so on.\n\nneigh_map = {\n    'MeadowV': 1,\n    'IDOTRR': 1,\n    'BrDale': 1,\n    'BrkSide': 2,\n    'OldTown': 2,\n    'Edwards': 2,\n    'Sawyer': 3,\n    'Blueste': 3,\n    'SWISU': 3,\n    'NPkVill': 3,\n    'NAmes': 3,\n    'Mitchel': 4,\n    'SawyerW': 5,\n    'NWAmes': 5,\n    'Gilbert': 5,\n    'Blmngtn': 5,\n    'CollgCr': 5,\n    'ClearCr': 6,\n    'Crawfor': 6,\n    'Veenker': 7,\n    'Somerst': 7,\n    'Timber': 8,\n    'StoneBr': 9,\n    'NridgHt': 10,\n    'NoRidge': 10\n}\n\ndataset['Neighborhood'] = dataset['Neighborhood'].map(neigh_map).astype('Int64')\next_map = {'Po': 1, 'Fa': 2, 'TA': 3, 'Gd': 4, 'Ex': 5}\ndataset['ExterQual'] = dataset['ExterQual'].map(ext_map).astype('Int64')\ndataset['ExterCond'] = dataset['ExterCond'].map(ext_map).astype('Int64')\nbsm_map = {'None': 0, 'Po': 1, 'Fa': 2, 'TA': 3, 'Gd': 4, 'Ex': 5}\ndataset['BsmtQual'] = dataset['BsmtQual'].map(bsm_map).astype('Int64')\ndataset['BsmtCond'] = dataset['BsmtCond'].map(bsm_map).astype('Int64')\nbsmf_map = {\n    'None': 0,\n    'Unf': 1,\n    'LwQ': 2,\n    'Rec': 3,\n    'BLQ': 4,\n    'ALQ': 5,\n    'GLQ': 6\n}\n\ndataset['BsmtFinType1'] = dataset['BsmtFinType1'].map(bsmf_map).astype('Int64')\ndataset['BsmtFinType2'] = dataset['BsmtFinType2'].map(bsmf_map).astype('Int64')\nheat_map = {'Po': 1, 'Fa': 2, 'TA': 3, 'Gd': 4, 'Ex': 5}\ndataset['HeatingQC'] = dataset['HeatingQC'].map(heat_map).astype('Int64')\ndataset['KitchenQual'] = dataset['KitchenQual'].map(heat_map).astype('Int64')\ndataset['FireplaceQu'] = dataset['FireplaceQu'].map(bsm_map).astype('Int64')\ndataset['GarageCond'] = dataset['GarageCond'].map(bsm_map).astype('Int64')\ndataset['GarageQual'] = dataset['GarageQual'].map(bsm_map).astype('Int64')","metadata":{"execution":{"iopub.status.busy":"2022-09-07T14:05:03.281264Z","iopub.execute_input":"2022-09-07T14:05:03.282140Z","iopub.status.idle":"2022-09-07T14:05:03.323972Z","shell.execute_reply.started":"2022-09-07T14:05:03.282106Z","shell.execute_reply":"2022-09-07T14:05:03.323073Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"**2.4 Create new features**","metadata":{}},{"cell_type":"code","source":"# Creating new features based on previous observations\n# For example: a new feature was created that groups all types of Bathrooms into one.\n\ndataset['TotalSF'] = (dataset['BsmtFinSF1'] + dataset['BsmtFinSF2'] +\n                       dataset['1stFlrSF'] + dataset['2ndFlrSF'])\ndataset['TotalBathrooms'] = (dataset['FullBath'] +\n                              (0.5 * dataset['HalfBath']) +\n                              dataset['BsmtFullBath'] +\n                              (0.5 * dataset['BsmtHalfBath']))\n\ndataset['TotalPorchSF'] = (dataset['OpenPorchSF'] + dataset['3SsnPorch'] +\n                            dataset['EnclosedPorch'] +\n                            dataset['ScreenPorch'] + dataset['WoodDeckSF'])\n\ndataset['YearBlRm'] = (dataset['YearBuilt'] + dataset['YearRemodAdd'])\n\n# Fusion of quality and conditions\n\ndataset['TotalExtQual'] = (dataset['ExterQual'] + dataset['ExterCond'])\ndataset['TotalBsmQual'] = (dataset['BsmtQual'] + dataset['BsmtCond'] +\n                            dataset['BsmtFinType1'] +\n                            dataset['BsmtFinType2'])\ndataset['TotalGrgQual'] = (dataset['GarageQual'] + dataset['GarageCond'])\ndataset['TotalQual'] = dataset['OverallQual'] + dataset['TotalExtQual'] + dataset['TotalBsmQual'] + dataset[\n        'TotalGrgQual'] + dataset['KitchenQual'] + dataset['HeatingQC']\n\n# Creation of new functions by using new quality indicators\n\ndataset['QualGr'] = dataset['TotalQual'] * dataset['GrLivArea']\ndataset['QualBsm'] = dataset['TotalBsmQual'] * (dataset['BsmtFinSF1'] +\n                                                  dataset['BsmtFinSF2'])\ndataset['QualPorch'] = dataset['TotalExtQual'] * dataset['TotalPorchSF']\ndataset['QualExt'] = dataset['TotalExtQual'] * dataset['MasVnrArea']\ndataset['QualGrg'] = dataset['TotalGrgQual'] * dataset['GarageArea']\ndataset['QlLivArea'] = (dataset['GrLivArea'] -\n                         dataset['LowQualFinSF']) * (dataset['TotalQual'])\ndataset['QualSFNg'] = dataset['QualGr'] * dataset['Neighborhood']\n\n\n# Creating some simple features\n\ndataset['HasPool'] = dataset['PoolArea'].apply(lambda x: 1 if x > 0 else 0)\ndataset['Has2ndFloor'] = dataset['2ndFlrSF'].apply(lambda x: 1 if x > 0 else 0)\ndataset['HasGarage'] = dataset['QualGrg'].apply(lambda x: 1 if x > 0 else 0)\ndataset['HasBsmt'] = dataset['QualBsm'].apply(lambda x: 1 if x > 0 else 0)\ndataset['HasFireplace'] = dataset['Fireplaces'].apply(lambda x: 1 if x > 0 else 0)\ndataset['HasPorch'] = dataset['QualPorch'].apply(lambda x: 1 if x > 0 else 0)","metadata":{"execution":{"iopub.status.busy":"2022-09-07T14:05:03.325353Z","iopub.execute_input":"2022-09-07T14:05:03.325919Z","iopub.status.idle":"2022-09-07T14:05:03.368323Z","shell.execute_reply.started":"2022-09-07T14:05:03.325874Z","shell.execute_reply":"2022-09-07T14:05:03.367363Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"##Transformando los datos\n#Algunos de los valores continuos no se distribuyen de manera uniforme y no se ajustan a la distribución normal- \n# podemos solucionarlos mediante el uso de enfoques de transformación de pareja. Vamos a usar boxcox\n\npossible_skewed = ['LotFrontage', 'LotArea', 'MasVnrArea', 'BsmtFinSF1', 'BsmtFinSF2',\n                    'BsmtUnfSF', 'TotalBsmtSF', '1stFlrSF', '2ndFlrSF', 'GrLivArea',\n                    'GarageArea', 'WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch', '3SsnPorch',\n                    'ScreenPorch', 'PoolArea', 'LowQualFinSF', 'MiscVal']\n\n# Encontrar la asimetría de las características numéricas.\n\nskew_features = np.abs(dataset[possible_skewed].apply(lambda x: skew(x)).sort_values(\n    ascending=False))\n\n# Filtrado de características sesgadas.\n\nhigh_skew = skew_features[skew_features > 0.3]\n\n# Toma de índices de alto sesgo.\n\nskew_index = high_skew.index\n\n# Aplicar la transformación boxcox para corregir la asimetría.\n\nfor i in skew_index:\n    dataset[i] = boxcox1p(dataset[i], boxcox_normmax(dataset[i] + 1))\n","metadata":{"execution":{"iopub.status.busy":"2022-09-07T14:05:03.369782Z","iopub.execute_input":"2022-09-07T14:05:03.370349Z","iopub.status.idle":"2022-09-07T14:05:03.541160Z","shell.execute_reply.started":"2022-09-07T14:05:03.370299Z","shell.execute_reply":"2022-09-07T14:05:03.539715Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# Label encoding of categorical variables\n\ndataset = pd.get_dummies(data=dataset)\n","metadata":{"execution":{"iopub.status.busy":"2022-09-07T14:05:03.542554Z","iopub.execute_input":"2022-09-07T14:05:03.542932Z","iopub.status.idle":"2022-09-07T14:05:03.595434Z","shell.execute_reply.started":"2022-09-07T14:05:03.542869Z","shell.execute_reply":"2022-09-07T14:05:03.594367Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# We check, before starting with the modeling\n\ndataset.drop(columns='SalePrice', inplace=True)\nprint(f'Number of missing values: {dataset.isna().sum().sum()}')","metadata":{"execution":{"iopub.status.busy":"2022-09-07T14:05:03.597179Z","iopub.execute_input":"2022-09-07T14:05:03.597510Z","iopub.status.idle":"2022-09-07T14:05:03.616046Z","shell.execute_reply.started":"2022-09-07T14:05:03.597478Z","shell.execute_reply":"2022-09-07T14:05:03.614978Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"# 3. Modeling","metadata":{}},{"cell_type":"code","source":"# Separate the dataset\ntrain = dataset.iloc[:len(y), :]\ntest = dataset.iloc[len(train):, :]\n\nprint(len(test))\nprint(len(train))","metadata":{"execution":{"iopub.status.busy":"2022-09-07T14:05:03.617727Z","iopub.execute_input":"2022-09-07T14:05:03.618476Z","iopub.status.idle":"2022-09-07T14:05:03.626538Z","shell.execute_reply.started":"2022-09-07T14:05:03.618430Z","shell.execute_reply":"2022-09-07T14:05:03.625218Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"X = train\nX_test = test\ny = np.log1p(y)","metadata":{"execution":{"iopub.status.busy":"2022-09-07T14:05:03.628265Z","iopub.execute_input":"2022-09-07T14:05:03.629517Z","iopub.status.idle":"2022-09-07T14:05:03.639686Z","shell.execute_reply.started":"2022-09-07T14:05:03.629422Z","shell.execute_reply":"2022-09-07T14:05:03.638733Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"# Configuration of kfold for future use.\nkf = KFold(10, random_state=42, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2022-09-07T14:05:03.640937Z","iopub.execute_input":"2022-09-07T14:05:03.642094Z","iopub.status.idle":"2022-09-07T14:05:03.653168Z","shell.execute_reply.started":"2022-09-07T14:05:03.642061Z","shell.execute_reply":"2022-09-07T14:05:03.652130Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"**3.1 Models**","metadata":{}},{"cell_type":"code","source":"alphas_alt = [30.5, 20.6, 20.7, 20.8, 20.9, 20, 20.1, 20.2, 20.3, 20.4, 20.5]\nalphas2 = [0.01]\ne_alphas = [0.01]\ne_l1ratio = [0.8, 0.85, 0.9, 0.95, 0.99, 1]\n\n# ridge_cv:\nridge = make_pipeline(RobustScaler(), RidgeCV(\n    alphas=alphas_alt,\n    cv=kf,))\n\n# lasso_cv:\nlasso = make_pipeline(\n    RobustScaler(),\n    LassoCV(max_iter=1e3, alphas=alphas2, random_state=42, cv=kf))\n\n# elasticnet_cv:\nelasticnet = make_pipeline(\n    RobustScaler(),\n    ElasticNetCV(max_iter=1e3,\n                 alphas=e_alphas,\n                 cv=kf,\n                 random_state=42,\n                 l1_ratio=e_l1ratio))\n\n# svr:\nsvr = make_pipeline(RobustScaler(),\n                    SVR(C=21, epsilon=0.0099, gamma=0.00017, tol=0.000121))\n\n# gradientboosting:\ngbr = GradientBoostingRegressor(n_estimators=2900,\n                                learning_rate=0.0161,\n                                max_depth=4,\n                                max_features='sqrt',\n                                min_samples_leaf=17,\n                                loss='huber',\n                                random_state=42)\n\n# lightgbm:\nlightgbm = LGBMRegressor(objective='regression',\n                         n_estimators=3500,\n                         num_leaves=5,\n                         learning_rate=0.00721,\n                         max_bin=163,\n                         bagging_fraction=0.35711,\n                         n_jobs=-1,\n                         bagging_seed=42,\n                         feature_fraction_seed=42,\n                         bagging_freq=7,\n                         feature_fraction=0.1294,\n                         min_data_in_leaf=8)\n\n# xgboost:\nxgboost = XGBRegressor(\n    learning_rate =0.0139,\n    n_estimators =4500,\n    max_depth =4,\n    min_child_weight =0,\n    subsample =0.7968,\n    colsample_bytree =0.4064,\n    nthread =-1,\n    scale_pos_weight =2,\n    seed=42,\n    enable_categorical=True)\n\n\n# histgradientboost:\nhgrd= HistGradientBoostingRegressor(loss= 'least_squares',\n    max_depth = 2,\n    min_samples_leaf = 40,\n    max_leaf_nodes = 29,\n    learning_rate = 0.15,\n    max_iter = 500,\n    random_state=42)\n\n#tweedie regresson:\ntweed = make_pipeline(RobustScaler(),TweedieRegressor(alpha=0.005))\n\n\n# stacking regressor:\nstack_gen = StackingCVRegressor(regressors=(ridge, lasso, elasticnet, gbr,\n                                            xgboost, lightgbm,hgrd, tweed),\n                                            meta_regressor=xgboost,\n                                            use_features_in_secondary=True)","metadata":{"execution":{"iopub.status.busy":"2022-09-07T14:05:03.654565Z","iopub.execute_input":"2022-09-07T14:05:03.657871Z","iopub.status.idle":"2022-09-07T14:05:03.675756Z","shell.execute_reply.started":"2022-09-07T14:05:03.657835Z","shell.execute_reply":"2022-09-07T14:05:03.674567Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"**3.2 Cross validation**","metadata":{}},{"cell_type":"code","source":"def model_check(X, y, estimators, cv):\n    \n    ''' A function for testing multiple estimators.'''\n    \n    model_table = pd.DataFrame()\n\n    row_index = 0\n    for est, label in zip(estimators, labels):\n\n        MLA_name = label\n        model_table.loc[row_index, 'Model Name'] = MLA_name\n\n        cv_results = cross_validate(est,\n                                    X,\n                                    y,\n                                    cv=cv,\n                                    scoring='neg_root_mean_squared_error',\n                                    return_train_score=True,\n                                    n_jobs=-1)\n\n        model_table.loc[row_index, 'Train RMSE'] = -cv_results[\n            'train_score'].mean()\n        model_table.loc[row_index, 'Test RMSE'] = -cv_results[\n            'test_score'].mean()\n        model_table.loc[row_index, 'Test Std'] = cv_results['test_score'].std()\n        model_table.loc[row_index, 'Time'] = cv_results['fit_time'].mean()\n\n        row_index += 1\n        print(\"--------\")\n\n    model_table.sort_values(by=['Test RMSE'],\n                            ascending=True,\n                            inplace=True)\n\n    return model_table","metadata":{"execution":{"iopub.status.busy":"2022-09-07T14:05:03.677197Z","iopub.execute_input":"2022-09-07T14:05:03.677659Z","iopub.status.idle":"2022-09-07T14:05:03.696812Z","shell.execute_reply.started":"2022-09-07T14:05:03.677617Z","shell.execute_reply":"2022-09-07T14:05:03.695253Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"# Setting list of estimators and labels for them.\n\nestimators = [ridge, lasso, elasticnet, gbr, xgboost, lightgbm, svr, hgrd, tweed]\nlabels = [\n    'Ridge', 'Lasso', 'Elasticnet', 'GradientBoostingRegressor',\n    'XGBRegressor', 'LGBMRegressor', 'SVR', 'HistGradientBoostingRegressor','TweedieRegressor'\n]","metadata":{"execution":{"iopub.status.busy":"2022-09-07T14:05:03.698039Z","iopub.execute_input":"2022-09-07T14:05:03.699055Z","iopub.status.idle":"2022-09-07T14:05:03.709512Z","shell.execute_reply.started":"2022-09-07T14:05:03.699020Z","shell.execute_reply":"2022-09-07T14:05:03.708435Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"# Executing cross validation.\n\nraw_models = model_check(X, y, estimators, kf)\ndisplay(raw_models.style.background_gradient(cmap='summer_r'))","metadata":{"execution":{"iopub.status.busy":"2022-09-07T14:05:03.710751Z","iopub.execute_input":"2022-09-07T14:05:03.711090Z","iopub.status.idle":"2022-09-07T14:06:34.343046Z","shell.execute_reply.started":"2022-09-07T14:05:03.711060Z","shell.execute_reply":"2022-09-07T14:06:34.341796Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":"**3.3 Stacking**","metadata":{}},{"cell_type":"code","source":"# Stack and mix.\n# Here we fit each estimator we have in the train data and then combine them by assigning weights to each model and summing the results.\n# Weights are quite subjective.\n\nprint('=' * 20, 'START Fitting', '=' * 20)\nprint('=' * 55)\n\n#print(datetime.now(), 'StackingCVRegressor')\n#stack_gen_model = stack_gen.fit(X.values, y.values)\n\nprint(datetime.now(), 'Elasticnet')\nelastic_model_full_data = elasticnet.fit(X, y)\n\nprint(datetime.now(), 'Lasso')\nlasso_model_full_data = lasso.fit(X, y)\n\nprint(datetime.now(), 'Ridge')\nridge_model_full_data = ridge.fit(X, y)\n\nprint(datetime.now(), 'SVR')\nsvr_model_full_data = svr.fit(X, y)\n\nprint(datetime.now(), 'GradientBoosting')\ngbr_model_full_data = gbr.fit(X, y)\n\n#print(datetime.now(), 'XGboost')\n#xgb_model_full_data = xgboost.fit(X, y)\n\n#print(datetime.now(), 'Lightgbm')\n#lgb_model_full_data = lightgbm.fit(X, y)\n\nprint(datetime.now(), 'Hist')\nhist_full_data = hgrd.fit(X, y)\n\nprint(datetime.now(), 'Tweed')\ntweed_full_data = tweed.fit(X, y)\n\nprint('=' * 20, 'FINISHED Fitting', '=' * 20)\nprint('=' * 58)","metadata":{"execution":{"iopub.status.busy":"2022-09-07T14:06:34.344777Z","iopub.execute_input":"2022-09-07T14:06:34.345166Z","iopub.status.idle":"2022-09-07T14:06:57.300824Z","shell.execute_reply.started":"2022-09-07T14:06:34.345134Z","shell.execute_reply":"2022-09-07T14:06:57.296936Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":"**3.4 Evaluation of models**","metadata":{}},{"cell_type":"code","source":"# Get the Predictions and Evaluate the accuracy of each model (in 3 different ways)\n\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.metrics import mean_squared_error\n\n\nprint(\"\\nelastic_model_full_data\")\ny1 = elastic_model_full_data.predict(X)\nprint(\"MAE\",mean_absolute_error(y1, y))\nprint(\"MSE\",mean_squared_error(y1, y))\nprint(\"RMSE\",np.sqrt(mean_squared_error(y1, y)))\n\nprint(\"\\nlasso_model_full_data\")\ny2 = lasso_model_full_data.predict(X)\nprint(\"MAE\",mean_absolute_error(y2, y))\nprint(\"MSE\",mean_squared_error(y2, y))\nprint(\"RMSE\",np.sqrt(mean_squared_error(y2, y)))\n\nprint(\"\\nridge_model_full_data\")\ny3 = ridge_model_full_data.predict(X)\nprint(\"MAE\",mean_absolute_error(y3, y))\nprint(\"MSE\",mean_squared_error(y3, y))\nprint(\"RMSE\",np.sqrt(mean_squared_error(y3, y)))\n\nprint(\"\\nsvr_model_full_data\")\ny4 = svr_model_full_data.predict(X)\nprint(\"MAE\",mean_absolute_error(y4, y))\nprint(\"MSE\",mean_squared_error(y4, y))\nprint(\"RMSE\",np.sqrt(mean_squared_error(y4, y)))\n\nprint(\"\\ngbr_model_full_data\")\ny5 = gbr_model_full_data.predict(X)\nprint(\"MAE\",mean_absolute_error(y5, y))\nprint(\"MSE\",mean_squared_error(y5, y))\nprint(\"RMSE\",np.sqrt(mean_squared_error(y5, y)))\n\nprint(\"\\nhist_full_data\")\ny6 = hist_full_data.predict(X)\nprint(\"MAE\",mean_absolute_error(y6, y))\nprint(\"MSE\",mean_squared_error(y6, y))\nprint(\"RMSE\",np.sqrt(mean_squared_error(y6, y)))\n\nprint(\"\\ntweed_full_data\")\ny7 = tweed_full_data.predict(X)\nprint(\"MAE\",mean_absolute_error(y7, y))\nprint(\"MSE\",mean_squared_error(y7, y))\nprint(\"RMSE\",np.sqrt(mean_squared_error(y7, y)))","metadata":{"execution":{"iopub.status.busy":"2022-09-07T14:06:57.302645Z","iopub.execute_input":"2022-09-07T14:06:57.306197Z","iopub.status.idle":"2022-09-07T14:06:58.416004Z","shell.execute_reply.started":"2022-09-07T14:06:57.306161Z","shell.execute_reply":"2022-09-07T14:06:58.413651Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"# Combine models (giving each one a weight)\n\ndef blend_models_predict(X):\n    return ((0.05 * elastic_model_full_data.predict(X)) +\n            (0.05 * lasso_model_full_data.predict(X)) +\n            (0.25 * ridge_model_full_data.predict(X)) +\n            (0.25 * svr_model_full_data.predict(X)) +\n            (0.05 * gbr_model_full_data.predict(X)) +\n            (0.1 * hist_full_data.predict(X)) +\n            (0.25 * tweed_full_data.predict(X)))","metadata":{"execution":{"iopub.status.busy":"2022-09-07T14:06:58.418289Z","iopub.execute_input":"2022-09-07T14:06:58.418968Z","iopub.status.idle":"2022-09-07T14:06:58.436078Z","shell.execute_reply.started":"2022-09-07T14:06:58.418890Z","shell.execute_reply":"2022-09-07T14:06:58.429559Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"# Our models are adjusted, stacked and combined so that we can predict and send our results.\n\nsubmission = pd.read_csv('/kaggle/input/house-prices-advanced-regression-techniques/test.csv')\n\nsubmission['SalePrice'] = np.floor(np.expm1(blend_models_predict(X_test)))","metadata":{"execution":{"iopub.status.busy":"2022-09-07T14:06:58.438286Z","iopub.execute_input":"2022-09-07T14:06:58.438860Z","iopub.status.idle":"2022-09-07T14:06:59.539674Z","shell.execute_reply.started":"2022-09-07T14:06:58.438808Z","shell.execute_reply":"2022-09-07T14:06:59.537803Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"markdown","source":"**3.5 Dataframe creation and saving**","metadata":{}},{"cell_type":"code","source":"# Creating delivery dataframe.\n\nsubmission = submission[['Id', 'SalePrice']]\n\n# Saving as a csv file:\n\nsubmission.to_csv('mysubmission.csv', index=False)\n\nprint('Saving submission.',datetime.now(),)\nsubmission.head()","metadata":{"execution":{"iopub.status.busy":"2022-09-07T14:06:59.541823Z","iopub.execute_input":"2022-09-07T14:06:59.542390Z","iopub.status.idle":"2022-09-07T14:06:59.585716Z","shell.execute_reply.started":"2022-09-07T14:06:59.542336Z","shell.execute_reply":"2022-09-07T14:06:59.581637Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}